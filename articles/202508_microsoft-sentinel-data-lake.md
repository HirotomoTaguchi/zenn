---
title: "Microsoft Sentinel Data Lakeでコスパ良くセキュリティログを長期保管する"
emoji: "🛡" 
type: "tech" ## tech: 技術記事 / idea: アイデア記事
topics: [Microsoft Defender, Security, Microsoft Sentinel] 
published: true
---

最近、マイクロソフトから Microsoft Sentinel Data Lake がパブリックプレビューとして発表されました^[[](https://techcommunity.microsoft.com/blog/microsoft-security-blog/introducing-microsoft-sentinel-data-lake/4434280)] 。このデータレイクを使うことで、より簡単に、コスパよくデータの長期保存ができるようになります。そこで今回は、データレイク機能について掘り下げていきます。

:::message
本記事は2025年8月13日時点の情報で執筆されています。また、この機能は現在パブリックプレビューです。本記事は、環境でのいかなる設定エラーやデータ損失に対しても責任を負いかねます。まずは小規模なテスト環境での評価から始めることをお勧めします。
:::

## セキュリティログ管理のジレンマ

世界全体のデータ量が年々爆増しているとはよく言われていることですが、それに伴いセキュリティログも急激に増加し、多くのセキュリティチームは厳しい選択を迫られています。全部のログを永久的に分析可能な状態（Sentinelでいう分析層＝Analytics Tier）で保管すると膨大な費用が掛かるので、ログ収集範囲を縮小して死角を作るか、追従性・監査性を犠牲にして保持期間を短縮するなどの対応策で工面している会社は多いのではないかと思います。

あるいは、SIEMに取り込まずSyslogサーバーやBlobストレージなどに別保管するなどの対応をしている企業もありますが、これは「安かろう・悪かろう」という感覚で、ひとたび調査が必要となった場合には分析基盤への取り込みが必要となり効率的とは言えませんし、定常的な監視・アラート検出には不向きです。お金のあるエンプラだったら、金に物を言わせて全てのログを分析層で保管して解決することもありますが持続可能ではありませんし、コスパがいいとは言えません。

## Microsoft Sentinel Data Lake

そんな中、登場したMicrosoft Sentinel Data Lakeでは、より安く・簡単にデータを長期保管することができます。加えて、通常のSentinelの保管先である「分析層」と比較して制限はあるものの、KQLを利用したクエリにも対応しており、インシデント発生時等に長期保管していたログから「何か」を取り出したいときに最適な基盤となっています。

## 分析層とデータレイク層の比較

分析層とデータレイク層、およびそれぞれの主要な特徴については、MS社がまとめていた表が非常に分かりやすかったので引用してきました。^[[分析層とデータレイク層を比較する](https://learn.microsoft.com/en-us/azure/sentinel/manage-data-overview)]手抜きではないです。

| 項目 | 分析層（Analytics Tier） | データレイク層（Data Lake Tier） |
| :--- | :--- | :--- |
| **主な特徴** | ログの高性能クエリとインデックス作成（ホットまたはインタラクティブ保持とも呼ばれる） | 大量データのコスト効率的な長期保持（コールドストレージとも呼ばれる） |
| **最適な用途** | リアルタイム分析ルール、アラート、ハンティング、ワークブック、およびすべてのMicrosoft Sentinel機能 | コンプライアンスおよび規制ロギング、履歴トレンド分析とフォレンジック、リアルタイムアラートが不要なあまり触れられないデータ |
| **取り込みコスト** | 標準 | 最小限 |
| **クエリ価格** | 込み ✅ | 別途課金 ❌ |
| **最適化されたクエリパフォーマンス** | ✅ | クエリが遅い ❌ 監査に適しているが、リアルタイム分析には最適化されていない |
| **クエリ機能** | Microsoft DefenderおよびAzureポータルでの完全なクエリ機能、およびAPIの使用 | 単一テーブルでの完全なKQL（ルックアップを使用して分析テーブルのデータで拡張可能）、スケジュールされたKQLまたはSparkジョブの実行、ノートブックの使用 |
| **リアルタイム分析機能** | フルセット ✅ | 制限あり ❌ 分析ルール、ハンティングクエリ、パーサー、ウォッチリスト、ワークブック、プレイブックなどの一部機能に制限 |
| **検索ジョブ** | ✅ | ✅ |
| **サマリー ルール** | ✅ | ✅ |
| **KQL** | フル機能 | 単一テーブルに限定 |
| **復元** | ✅ | ❌ |
| **データエクスポート** | ✅ | ❌ |
| **保持期間** | Microsoft Sentinelは90日間、Microsoft Defender XDRは30日間。比例配分された月額長期保持料金で最大2年まで延長可能 | デフォルトでは分析保持と同じ。最大12年まで延長可能 |

:::message
「復元」が何を指しているのかはあまりわかっていないので調査中です。データを分析層に持ってくることであれば、Data Lake Tierでできますが、データの復元先としてりようできるかということでしょうか？
:::

ちなみに、コストについては単純比較できませんが、Sentinelの従量課金（Pay-as-you-go）で分析層に取り込んだ場合1GBあたり$4.3 USDかかりますが、データレイクでは取り込みに1GBあたり$0.05、格納データに対して1GBあたり0.026ドル/月となっています。^[[microsoft-sentinel-data-lake-pricing-preview](https://techcommunity.microsoft.com/blog/microsoft-security-blog/microsoft-sentinel-data-lake-pricing-preview/4433919)]

:::message
当たり前ですが、分析層とデータレイクでは実現できることが異なり、Apple2Appleの比較ではない点にご留意ください。代表的な例としてはデータレイクではKQLを使ったクエリにも追加費用が発生したりします。マイクロソフト社の公式情報では従来の10％未満という記載があったので、そちらを目安の金額にしていただけたらいいかと思いますが、実際のコストは自社のユースケースに応じて試算いただけますと幸いです。
:::

## Microsoft Sentinelデータレイクを使ってみる

### 前提条件

Microsoft Sentinelデータレイクのパブリックプレビューにオンボードするには、以下の前提条件を満たす必要があります。

- Microsoft DefenderとMicrosoft SentinelがDefender XDRに統合されて利用可能であること
- データレイクの請求用の既存のAzureサブスクリプションとリソースグループがあること、サブスクリプションの所有者権限を持っていること
- Microsoft DefenderポータルにMicrosoft Sentinelプライマリワークスペースが接続されていること
- プライマリおよびその他のワークスペースへの読み取り権限があり、データレイクにアタッチできることが必要です。
- Microsoft Sentinelプライマリワークスペースとその他のワークスペースがテナントのホームリージョンと同じリージョンにあること（パブリックプレビューの制約）

:::message
パブリックプレビューの制約として、Sentinelのプライマリワークスペースはテナント（EntraID）と同じ地理的リージョンにある必要があります。EntraIDというのがポイントで、多くの日本のユーザーはDefenderのログの保管先をUSに指定しているかと思いますが、EntraIDは日本になっているかと思います（ややこしや・・・）。なので、Sentinelのワークスペースを東日本で構成して試してください。また、パブリックプレビューではすべてのリージョンがサポートされているわけではないことにご注意ください。
:::

### オンボーディング（初期設定）^[[Microsoft Sentinel でテーブル設定を構成する (プレビュー)](https://learn.microsoft.com/en-us/azure/sentinel/manage-table-tiers-retention)]

テナントをMicrosoft Sentinelデータレイクにオンボードする手順は簡単です。前提条件として、SIEMワークスペース機能を通じてSentinelをDefenderポータルに接続します。こちらについては、前職時代にブログを書いているのでそちらを参照ください。

https://blog.cloudnative.co.jp/24112/

続いて、Defender XDRポータル（ https://security.microsoft.com ）で、[システム] > [設定] > [Microsoft Sentinel] > [データレイク] のデータレイク設定ページに遷移します。すべての前提条件が満たされると、接続ボタンが表示されます。「セットアップの開始」ボタンをクリックすると、設定の画面が起動します。すべての情報を入力したら、「データレイクのセットアップ」をクリックします。データレイクが完全に作成され、Defenderテナントにリンクされるまでに最大60分かかります。

![](https://github.com/user-attachments/assets/efb24216-ad34-4139-90ed-7ed68c6f99a4)

プロセスが進行中の場合、「レイクのセットアップが進行中」というメッセージが表示されます。しばらく待つと、データレイクのセットアップが完了します。

![](https://github.com/user-attachments/assets/ed48fe83-934e-4985-921d-5eeaa2f60103)

ちなみに、セットアップが完了すると、Defender XDRに新しいデータレイク探索ビューが表示されます。また、その際「default」という名前のワークスペースが作成されます。KQLクエリのワークスペースセレクターに表示される「Default」ワークスペースは、オンボード時にMicrosoft Sentinelデータレイクによって作成されます。

###  データレイク層でログを長期保管する

Microsoft Sentinelにログを取り込むデータコネクタは、規定では分析層と長期保存用のデータレイク層の両方にデータを送信するように構成されています。Sentinelデータコネクタが有効になると、データは分析層にプッシュされ、データレイク層に自動的にミラーリングされます。分析層と同じ保持期間でデータレイクにデータをミラーリングしても、追加の請求料金は発生しません。^[[configure-data-connector?tabs=defender-portal](https://learn.microsoft.com/ja-jp/azure/sentinel/configure-data-connector?tabs=defender-portal)]

そして、データレイク設定後、以下の画像のように保持期間が延長された場合にのみ、データレイクとしてストレージに追加コストが発生します。設定は [Defender XDRポータル] > [Microsoft Sentinel] > [Configuration] > [Tables] でテーブル単位で実施できます。

![](https://github.com/user-attachments/assets/fb4dfeb6-add7-40a1-bcda-d1cbbff9166a)


### データレイク層に直接データを取り込む

別の方法として、データレイク層にのみデータを取り込むことも可能です。FWの生ログやEntraIDの [AADNonInteractiveUserSignInLogs] などは、分析層に直接取り込むと非常に高コストになります。新しいデータレイクを使用すると、データを直接データレイクにストリーミングし、Sentinelの分析層をスキップできます。これにより、データはデータレイク層にのみ取り込まれ、分析層への取り込みは停止され、データはデータレイクにのみ保存されます。

![](https://github.com/user-attachments/assets/e30a7bdb-4d8a-41e8-939f-5e513cd0467f)


### KQL queris

データレイク層の特徴として、データを貯めておくだけではなく、KQLクエリを実行するとログの調査を行うことができる点にあります。これは言葉にすると安っぽいですが、実は重要なことで、これまで安いストレージ（Blob等）にログを保管する場合、分析を行うためには分析用の基板に取り込んでから分析する必要があり手間でありました。一方、データレイクでは、価格を安く抑えながら、調査したい場合はクイックにクエリを実行できる点が非常に良きです。

![](https://github.com/user-attachments/assets/605384da-8771-4494-adf4-14c21a1df299)

:::message
データレイク層へのKQL実行は有料なのでその点に留意ください。また2つのテーブルをジョイントして検索などはできないので、その点にもご留意ください。
:::

### Serch & Restore

上述の通り、データレイク層においてのKQLを使った調査には制約がありますが、制約を取っ払ってガッツリと調査したい場合にはデータを分析層にリストアすることもできます。[Serch & Restore] のタブでテーブルと期間を選択し、データをリストアするとAdvanced Huntingでデータを調査できます。

![](https://github.com/user-attachments/assets/fe590368-0820-4286-bed6-0fa963d749d1)

しかしながら、下記のようにデータの形式はAdvanced Huntingに直接取り込んだ形式とは異なるので、その点には注意が必要です。

![](https://github.com/user-attachments/assets/86233030-5047-4b98-9eb0-83896290f982)

### Jobs

加えて、Jobs を使用して、データレイクから少量のデータを分析層に直接移動させることができます。ジョブは、データレイク層のデータに対してKQLクエリを実行し、結果を分析層に昇格させる機能です。単発または定期実行のスケジュールされたタスクを実行できます。

分析層のストレージは、データレイク層よりも高い請求レートが発生しますが、KQLを使用することで、データを削減・フィルタリングしてコストを節約しながら分析層に昇格できます。これにより、データ全体はデータレイク層に送りつつ、特定の条件でログが分析層に送信され、さらなるハンティングに利用できるようになります。

Jobs でデータを移動する際のテーブルはJobsで利用する専用のテーブルを利用(作成)する形となります。そのため、テーブル名が変わることに伴うクエリの変更等が後々発生する場合があるので注意が必要です。

![](https://github.com/user-attachments/assets/0eb72254-3233-44ab-b4ee-5519b5a66443)

Sentinelのワークスペースを選択して、クエリを書きます。

![](https://github.com/user-attachments/assets/0c64fd8c-c4e7-40dc-87cf-c3b4fec5083e)

スケジュール設定では、ワンショット・日時・週次・月次で実行スパンを選べます。

![](https://github.com/user-attachments/assets/032a0fcd-21bc-413f-a577-4a812f06c775)

ジョブが実行されると、完了したジョブは一覧で確認できます。

![](https://github.com/user-attachments/assets/22e85727-b688-4209-9502-fe41759bd799)

前述の通り、データを移行する際には別テーブルを作成（選択）するので、Advanced HuntingではCustamm Logsという形式で見ることになります。

![](https://github.com/user-attachments/assets/db775917-b20a-401d-b63b-aa856f112042)

## まとめ

これまでも、Blob等を使えば安くデータを長期保管できましたが、構築や運用を含めてコスパがいいとは言えませんでしたが、Data Lake の登場によりコスパが非常に良くなったように思います。また、興味深いのは、マイクロソフト社がこのデータレイクを単なる安い保管オプションではなく、「エージェント化された AI の導入を加速させるもの」と言っている点です。今だと、Data Lakeによるデータのサイロ化の抑制という価値が見えて来ていますが、そこから先のAIの活用についてもMSはビジョンを持って取り組んでいることが見えているので今後も注視していきたいです。
