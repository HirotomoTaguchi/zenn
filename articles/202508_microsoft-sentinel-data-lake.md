---
title: "Microsoft Sentinel Data Lake "
emoji: "🛡" 
type: "tech" ## tech: 技術記事 / idea: アイデア記事
topics: [Microsoft Defender, Security] 
published: false
---

最近、マイクロソフトから Microsoft Sentinel Data Lake がパブリックプレビューとして発表されました。このデータレイク機能を使うことで、従来よりもコストを抑えながら、より簡単にデータの拡張と保存ができるようになります。新しいMicrosoft Sentinelデータレイクは、設定が大幅に簡素化された、スケーラブルな次世代データレイクです。そこで今回は、データレイク機能について掘り下げていきます。

**注意事項**
この機能は現在パブリックプレビュー段階です。本記事は、環境でのいかなる設定エラーやデータ損失に対しても責任を負いかねます。まずは小規模なテスト環境での評価から始めることをお勧めします。

## セキュリティログ管理のジレンマ

セキュリティログの量が急激に増加する中、多くのチームが厳しい選択を迫られています。ログ収集範囲を縮小して死角を作るか、フォレンジック調査の精度を犠牲にして保持期間を短縮するか、あるいはSIEM内ですべてのセキュリティデータを管理しようとして持続不可能なコストを受け入れるかという三択です。

## Microsoft Sentinelデータレイク

新しいSentinelデータレイクによって、マイクロソフトはエージェント型防御のための新しい基盤をリリースし、マイクロソフト製品からのデータとサードパーティ製品からのデータをすべて統合できるようになりました。Sentinel上に構築され、Defender XDR内でセキュリティ専用に設計された、完全管理型のクラウドネイティブデータレイクが実現されました。この新しいデータレイクは完全に管理されているため、カスタムデータウェアハウスを構築する必要なく、すぐに利用開始できます。

## 分析層とデータレイク層の比較

分析層とデータレイク層、およびそれぞれの主要な特徴については、MS社の図が非常に分かりやすかったので引っ張ってきました。手抜きではないです。

| 項目 | 分析層 | データレイク層 |
| :--- | :--- | :--- |
| **主な特徴** | ログの高性能クエリとインデックス作成（ホットまたはインタラクティブ保持とも呼ばれる） | 大量データのコスト効率的な長期保持（コールドストレージとも呼ばれる） |
| **最適な用途** | リアルタイム分析ルール、アラート、ハンティング、ワークブック、およびすべてのMicrosoft Sentinel機能 | コンプライアンスおよび規制ロギング、履歴トレンド分析とフォレンジック、リアルタイムアラートが不要なあまり触れられないデータ |
| **取り込みコスト** | 標準 | 最小限 |
| **クエリ価格** | 込み ✅ | 別途課金 ❌ |
| **最適化されたクエリパフォーマンス** | ✅ | クエリが遅い ❌ 監査に適しているが、リアルタイム分析には最適化されていない |
| **クエリ機能** | Microsoft DefenderおよびAzureポータルでの完全なクエリ機能、およびAPIの使用 | 単一テーブルでの完全なKQL（ルックアップを使用して分析テーブルのデータで拡張可能）、スケジュールされたKQLまたはSparkジョブの実行、ノートブックの使用 |
| **リアルタイム分析機能** | フルセット ✅ | 制限あり ❌ 分析ルール、ハンティングクエリ、パーサー、ウォッチリスト、ワークブック、プレイブックなどの一部機能に制限 |
| **検索ジョブ** | ✅ | ✅ |
| **サマリー ルール** | ✅ | ✅ |
| **KQL** | フル機能 | 単一テーブルに限定 |
| **復元** | ✅ | ❌ |
| **データエクスポート** | ✅ | ❌ |
| **保持期間** | Microsoft Sentinelは90日間、Microsoft Defender XDRは30日間。比例配分された月額長期保持料金で最大2年まで延長可能 | デフォルトでは分析保持と同じ。最大12年まで延長可能 |

*出所: *

## データレイク層の課金



## Microsoft Sentinelデータレイクを使ってみる

### 前提条件

Microsoft Sentinelデータレイクのパブリックプレビューにオンボードするには、以下の前提条件を満たす必要があります。

Microsoft DefenderとMicrosoft SentinelがDefender XDRに統合されて利用可能であること、データレイクの請求用の既存のAzureサブスクリプションとリソースグループがあること、サブスクリプションの所有者権限を持っていること、Microsoft DefenderポータルにMicrosoft Sentinelプライマリワークスペースが接続されていること、Microsoft Sentinelプライマリワークスペースとその他のワークスペースがテナントのホームリージョンと同じリージョンにあること、プライマリおよびその他のワークスペースへの読み取り権限があり、データレイクにアタッチできることが必要です。

SentinelをDefender XDRポータルに接続してデータレイクにオンボードした場合、プライマリワークスペースはテナントのホーム地理的リージョンにある必要があります。つまり、DefenderとSentinelの両方で地理的リージョンが一致している必要があります。パブリックプレビューではすべてのリージョンがサポートされているわけではないことにご注意ください。

**注意:** パブリックプレビュー中は、プライマリおよびその他のワークスペースは、テナントのホームリージョンと同じリージョンにある必要があります。テナントのホームリージョンと同じリージョンにあるワークスペースのみをデータレイクにアタッチできます。

### オンボーディング（初期設定）

テナントをMicrosoft Sentinelデータレイクにオンボードする手順は簡単です。前提条件として、SIEMワークスペース機能を通じてSentinelをDefenderポータルに接続します。こちらについては、前職時代にブログを書いているのでそちらを参照ください。

https://blog.cloudnative.co.jp/24112/

続いて、Defender XDRポータル（https://security.microsoft.com）で、[システム] > [設定] > [Microsoft Sentinel] > [データレイク] のデータレイク設定ページに遷移し、セットアップを完了。ちなみに、必要なすべての前提条件に従ってテナントが設定されていない場合、エラーメッセージが表示されます。



すべての前提条件が満たされると、接続ボタンが表示されます。「セットアップの開始」ボタンをクリックすると、設定の画面が起動します。すべての情報を入力したら、「データレイクのセットアップ」をクリックします。データレイクが完全に作成され、Defenderテナントにリンクされるまでに最大60分かかります。



プロセスが進行中の場合、「レイクのセットアップが進行中」というメッセージが表示されます。しばらく待つと、データレイクのセットアップが完了します。



### Data Lakeにデータを蓄積する

セットアップが完了すると、Defender XDRに新しいデータレイク探索ビューが表示されます。また、その際「default」という名前のワークスペースが作成されます。KQLクエリのワークスペースセレクターに表示される「Default」ワークスペースは、オンボード時にMicrosoft Sentinelデータレイクによって作成されます。

Microsoft Sentinelデータコネクタは、分析層と長期保存用のデータレイク層の両方にデータを送信するように構成されています。

良い例として、Sentinelデータコネクタが有効になると、データは分析層にプッシュされ、データレイク層に自動的にミラーリングされます。

コネクタが有効になると、デフォルトでデータが自動的に分析層に送信され、データレイク層にミラーリングされることを理解しておくとよいでしょう。分析層と同じ保持期間でデータレイクにデータをミラーリングしても、追加の請求料金は発生しません。保持期間が延長された場合にのみ、ストレージに追加コストが発生し、KQLジョブを使用してデータを定期的にクエリし、結果を分析層に昇格させることができます。分析層に入ると、高度なKQL機能が利用可能になります。

### データレイク層に直接データを取り込む

別の方法として、データレイク層にのみデータを取り込むことも可能です。FWなどのログは、分析層に直接取り込むと非常に高コストになります。新しいデータレイクを使用すると、データを直接データレイクにストリーミングし、Sentinelの分析層をスキップできます。これにより、データはデータレイク層にのみ取り込まれ、分析層への取り込みは停止します。つまり、データはデータレイクにのみ保存されます。

### KQL queris

そして、KQLジョブを使用して、データレイクから少量のデータを分析層に直接移動させることができます。ジョブは、データレイク層のデータに対してKQLクエリを実行し、結果を分析層に昇格させる、単発または定期実行のスケジュールされたタスクです。分析層のストレージは、データレイク層よりも高い請求レートが発生します。

https://github.com/user-attachments/assets/605384da-8771-4494-adf4-14c21a1df299

KQLを使用することで、データを削減・フィルタリングしてコストを節約し、より多くのフィルタリングを行って分析層に昇格させることができます。これにより、ログは保持可能になり、特定のヒットが分析層に送信され、さらなるハンティングに利用できるようになります。

### Jobs

データレイクの機能として、クエリコストでレイクに対してKQLクエリを実行するオプションがあります。KQLジョブを使用すると、スケジュールされたタスクを実行できます。

### Serch & Restore



## まとめ

