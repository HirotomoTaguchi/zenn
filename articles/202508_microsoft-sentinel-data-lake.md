---
title: "Microsoft Sentinel Data Lakeでコスパ良くセキュリティログを長期保管する"
emoji: "🛡" 
type: "tech" ## tech: 技術記事 / idea: アイデア記事
topics: [Microsoft Defender, Security, Microsoft Sentinel] 
published: false
---

最近、マイクロソフトから Microsoft Sentinel Data Lake がパブリックプレビューとして発表されました。このデータレイクを使うことで、より簡単に、コスパよくデータの長期保存ができるようになります。そこで今回は、データレイク機能について掘り下げていきます。

**注意事項**
この機能は現在パブリックプレビュー段階です。本記事は、環境でのいかなる設定エラーやデータ損失に対しても責任を負いかねます。まずは小規模なテスト環境での評価から始めることをお勧めします。

## セキュリティログ管理のジレンマ

データのカンブリア爆発とはよく言ったものですが、デジタル機器が使用の爆増に伴い、セキュリティログの量が急激に増加する中、多くのセキュリティチームが厳しい選択を迫られています。全部のログを永久的に分析可能な状態（分析層）で保管すると膨大な費用が掛かるので、ログ収集範囲を縮小して死角を作るか、追従性・監査性を犠牲にして保持期間を短縮するなどの対応策が一般的です。

あるいは、SIEMに取り込まずSyslogサーバーやS3・Blobストレージなどに別保管するなどの対応をしている企業もありますが、ひとたび調査が必要となった場合に分析基盤への取り込みが必要となり効率的とは言えませんし監視には不向きです。お金のあるエンプラだったら、金に物を言わせて全部分析層で保管して解決することもありますが持続可能ではありません。

## Microsoft Sentinel Data Lake

そんな中、登場したMicrosoft Sentinel Data Lakeでは、より安く・簡単にデータを長期保管することができます。加えて、通常のSentinelの保管先である「分析層」と比較して制限はあるものの、KQLを利用したクエリにも対応しており、長期保管していたデータから「何か」を取り出したいときに最適な基盤となっています。

## 分析層とデータレイク層の比較

分析層とデータレイク層、およびそれぞれの主要な特徴については、MS社の図が非常に分かりやすかったので引っ張ってきました。手抜きではないです。

| 項目 | 分析層 | データレイク層 |
| :--- | :--- | :--- |
| **主な特徴** | ログの高性能クエリとインデックス作成（ホットまたはインタラクティブ保持とも呼ばれる） | 大量データのコスト効率的な長期保持（コールドストレージとも呼ばれる） |
| **最適な用途** | リアルタイム分析ルール、アラート、ハンティング、ワークブック、およびすべてのMicrosoft Sentinel機能 | コンプライアンスおよび規制ロギング、履歴トレンド分析とフォレンジック、リアルタイムアラートが不要なあまり触れられないデータ |
| **取り込みコスト** | 標準 | 最小限 |
| **クエリ価格** | 込み ✅ | 別途課金 ❌ |
| **最適化されたクエリパフォーマンス** | ✅ | クエリが遅い ❌ 監査に適しているが、リアルタイム分析には最適化されていない |
| **クエリ機能** | Microsoft DefenderおよびAzureポータルでの完全なクエリ機能、およびAPIの使用 | 単一テーブルでの完全なKQL（ルックアップを使用して分析テーブルのデータで拡張可能）、スケジュールされたKQLまたはSparkジョブの実行、ノートブックの使用 |
| **リアルタイム分析機能** | フルセット ✅ | 制限あり ❌ 分析ルール、ハンティングクエリ、パーサー、ウォッチリスト、ワークブック、プレイブックなどの一部機能に制限 |
| **検索ジョブ** | ✅ | ✅ |
| **サマリー ルール** | ✅ | ✅ |
| **KQL** | フル機能 | 単一テーブルに限定 |
| **復元** | ✅ | ❌ |
| **データエクスポート** | ✅ | ❌ |
| **保持期間** | Microsoft Sentinelは90日間、Microsoft Defender XDRは30日間。比例配分された月額長期保持料金で最大2年まで延長可能 | デフォルトでは分析保持と同じ。最大12年まで延長可能 |

*出所: *

## Microsoft Sentinelデータレイクを使ってみる

### 前提条件

Microsoft Sentinelデータレイクのパブリックプレビューにオンボードするには、以下の前提条件を満たす必要があります。

- Microsoft DefenderとMicrosoft SentinelがDefender XDRに統合されて利用可能であること
- データレイクの請求用の既存のAzureサブスクリプションとリソースグループがあること、サブスクリプションの所有者権限を持っていること
- Microsoft DefenderポータルにMicrosoft Sentinelプライマリワークスペースが接続されていること
- Microsoft Sentinelプライマリワークスペースとその他のワークスペースがテナントのホームリージョンと同じリージョンにあること
- プライマリおよびその他のワークスペースへの読み取り権限があり、データレイクにアタッチできることが必要です。

SentinelをDefender XDRポータルに接続してデータレイクにオンボードした場合、プライマリワークスペースはテナントのホーム地理的リージョンにある必要があります。つまり、DefenderとSentinelの両方で地理的リージョンが一致している必要があります。パブリックプレビューではすべてのリージョンがサポートされているわけではないことにご注意ください。


### オンボーディング（初期設定）

テナントをMicrosoft Sentinelデータレイクにオンボードする手順は簡単です。前提条件として、SIEMワークスペース機能を通じてSentinelをDefenderポータルに接続します。こちらについては、前職時代にブログを書いているのでそちらを参照ください。

https://blog.cloudnative.co.jp/24112/

続いて、Defender XDRポータル（ https://security.microsoft.com ）で、[システム] > [設定] > [Microsoft Sentinel] > [データレイク] のデータレイク設定ページに遷移します。すべての前提条件が満たされると、接続ボタンが表示されます。「セットアップの開始」ボタンをクリックすると、設定の画面が起動します。すべての情報を入力したら、「データレイクのセットアップ」をクリックします。データレイクが完全に作成され、Defenderテナントにリンクされるまでに最大60分かかります。

![](https://github.com/user-attachments/assets/efb24216-ad34-4139-90ed-7ed68c6f99a4)

プロセスが進行中の場合、「レイクのセットアップが進行中」というメッセージが表示されます。しばらく待つと、データレイクのセットアップが完了します。

![](https://github.com/user-attachments/assets/ed48fe83-934e-4985-921d-5eeaa2f60103)

ちなみに、セットアップが完了すると、Defender XDRに新しいデータレイク探索ビューが表示されます。また、その際「default」という名前のワークスペースが作成されます。KQLクエリのワークスペースセレクターに表示される「Default」ワークスペースは、オンボード時にMicrosoft Sentinelデータレイクによって作成されます。

### Data Lakeにデータを蓄積する

Microsoft Sentinelデータコネクタは、分析層と長期保存用のデータレイク層の両方にデータを送信するように構成されています。Sentinelデータコネクタが有効になると、データは分析層にプッシュされ、データレイク層に自動的にミラーリングされます。分析層と同じ保持期間でデータレイクにデータをミラーリングしても、追加の請求料金は発生しません。保持期間が延長された場合にのみ、ストレージに追加コストが発生し、KQLジョブを使用してデータを定期的にクエリし、結果を分析層に昇格させることができます。分析層に入ると、高度なKQL機能が利用可能になります。

### データレイク層に直接データを取り込む

別の方法として、データレイク層にのみデータを取り込むことも可能です。FWの生ログやEntraIDの [AADNonInteractiveUserSignInLogs] などは、分析層に直接取り込むと非常に高コストになります。新しいデータレイクを使用すると、データを直接データレイクにストリーミングし、Sentinelの分析層をスキップできます。これにより、データはデータレイク層にのみ取り込まれ、分析層への取り込みは停止され、データはデータレイクにのみ保存されます。

### KQL queris

データレイク層の特徴として、データを貯めておくだけではなく、KQLクエリを実行するとログの調査を行うことができる点にあります。これは言葉にすると安っぽいですが、実は重要なことで、これまで安いストレージ（Blob等）にログを保管する場合、分析を行うためには分析用の基板に取り込んでから分析する必要があり手間でありました。一方、データレイクでは、価格を安く抑えながら、調査したい場合はクイックにクエリを実行できる点が非常に良きです。

![](https://github.com/user-attachments/assets/605384da-8771-4494-adf4-14c21a1df299)

:::message
データレイク層へのKQL実行は有料なのでその点に留意ください。また2つのテーブルをジョイントして検索などはできないので、その点にもご留意ください。
:::

### Serch & Restore

上述の通り、データレイク層においてのKQLを使った調査には制約がありますが、制約を取っ払ってガッツリと調査したい場合にはデータを分析層にリストアすることもできます。[Serch & Restore] のタブでテーブルと期間を選択し、データをリストアするとAdvanced Huntingでデータを調査できます。

![](https://github.com/user-attachments/assets/fe590368-0820-4286-bed6-0fa963d749d1)

しかしながら、下記のようにデータの形式はAdvanced Huntingに直接取り込んだ形式とは異なるので、その点には注意が必要です。

![](https://github.com/user-attachments/assets/86233030-5047-4b98-9eb0-83896290f982)

### Jobs

加えて、Jobs を使用して、データレイクから少量のデータを分析層に直接移動させることができます。ジョブは、データレイク層のデータに対してKQLクエリを実行し、結果を分析層に昇格させる機能です。単発または定期実行のスケジュールされたタスクを実行できます。

分析層のストレージは、データレイク層よりも高い請求レートが発生しますが、KQLを使用することで、データを削減・フィルタリングしてコストを節約しながら分析層に昇格できます。これにより、データ全体はデータレイク層に送りつつ、特定の条件でログが分析層に送信され、さらなるハンティングに利用できるようになります。

Jobs でデータを移動する際のテーブルはJobsで利用する専用のテーブルを利用(作成)する形となります。そのため、テーブル名が変わることに伴うクエリの変更等が後々発生する場合があるので注意が必要です。

![](https://github.com/user-attachments/assets/0eb72254-3233-44ab-b4ee-5519b5a66443)

Sentinelのワークスペースを選択して、クエリを書きます。

![](https://github.com/user-attachments/assets/0c64fd8c-c4e7-40dc-87cf-c3b4fec5083e)

スケジュール設定では、ワンショット・日時・週次・月次で実行スパンを選べます。

![](https://github.com/user-attachments/assets/032a0fcd-21bc-413f-a577-4a812f06c775)

ジョブが実行されると、完了したジョブは一覧で確認できます。

![](https://github.com/user-attachments/assets/22e85727-b688-4209-9502-fe41759bd799)

前述の通り、データを移行する際には別テーブルを作成（選択）するので、Advanced HuntingではCustamm Logsという形式で見ることになります。

![](https://github.com/user-attachments/assets/db775917-b20a-401d-b63b-aa856f112042)

## まとめ

興味深いのは、マイクロソフト社がこのデータレイクのことを「」と言っている点です。
